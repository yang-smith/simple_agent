<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Client Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .form-group {
            margin-bottom: 15px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        input, select, textarea {
            width: 100%;
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-sizing: border-box;
        }
        button {
            background-color: #007bff;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin-right: 10px;
        }
        button:hover {
            background-color: #0056b3;
        }
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        .response {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border-left: 4px solid #007bff;
            white-space: pre-wrap;
            min-height: 100px;
        }
        .error {
            border-left-color: #dc3545;
            background-color: #f8d7da;
            color: #721c24;
        }
        .streaming {
            border-left-color: #28a745;
            background-color: #d4edda;
        }
        .info {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            color: #0c5460;
            padding: 10px;
            border-radius: 4px;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>LLM Client Test (Gateway)</h1>
        
        <div class="info">
            <strong>Gateway URL:</strong> https://my-llm-gateway.zy892065502.workers.dev<br>
            <strong>Auth Required:</strong> User token is required for all requests
        </div>
        
        <form id="testForm">
            <div class="form-group">
                <label for="userToken">User Token (Required):</label>
                <input type="password" id="userToken" placeholder="Enter your gateway user token" value="sk-gw-7f8a9b2c4d6e1f3a5b7c9d2e4f6a8b1c">
            </div>
            
            <div class="form-group">
                <label for="model">Model:</label>
                <select id="model">
                    <option value="openai/gpt-4o">OpenAI GPT-4o</option>
                    <option value="openai/gpt-3.5-turbo">OpenAI GPT-3.5 Turbo</option>
                    <option value="anthropic/claude-3-sonnet">Claude 3 Sonnet</option>
                    <option value="google/gemini-2.5-flash" selected>Google Gemini 2.5 Flash</option>
                    <option value="text-embedding-3-small">Text Embedding 3 Small</option>
                    <option value="perplexity/sonar">Perplexity Sonar (Web Search)</option>
                </select>
            </div>
            
            <div class="form-group">
                <label for="message">Message:</label>
                <textarea id="message" rows="4" placeholder="Enter your message here...">Hello! How are you today?</textarea>
            </div>
            
            <div class="form-group">
                <label for="temperature">Temperature:</label>
                <input type="number" id="temperature" min="0" max="2" step="0.1" value="0.7">
            </div>
            
            <div class="form-group">
                <label for="maxTokens">Max Tokens:</label>
                <input type="number" id="maxTokens" min="1" max="4000" value="1000">
            </div>
            
            <button type="button" id="testChat">Test Chat</button>
            <button type="button" id="testStream">Test Stream</button>
            <button type="button" id="testTools">Test Tools</button>
            <button type="button" id="clearResponse">Clear</button>
        </form>
        
        <div id="response" class="response" style="display: none;"></div>
    </div>

    <script type="module">
        import { LLMClient } from './src/llm/llm-client.js';
        import { initializeTools, getFunctionsXML, parseAndExecuteFunctionCalls } from './src/tools/index.js';
        
        const form = document.getElementById('testForm');
        const responseDiv = document.getElementById('response');
        const testChatBtn = document.getElementById('testChat');
        const testStreamBtn = document.getElementById('testStream');
        const testToolsBtn = document.getElementById('testTools');
        const clearBtn = document.getElementById('clearResponse');
        
        // åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ
        try {
            console.log('Initializing tools...');
            await initializeTools();
            console.log('Tools initialized successfully');
            
            // éªŒè¯å·¥å…·æ³¨å†Œ
            const { toolRegistry } = await import('./src/tools/registry.js');
            const toolNames = toolRegistry.getToolNames();
            console.log('Registered tools:', toolNames);
            
            const functionsXML = getFunctionsXML();
            console.log('Functions XML:', functionsXML);
            
            if (toolNames.length > 0) {
                console.log('âœ… Tools system ready');
            } else {
                console.warn('âš ï¸ No tools registered');
            }
        } catch (error) {
            console.error('âŒ Failed to initialize tools:', error);
        }
        
        function showResponse(content, isError = false, isStreaming = false) {
            responseDiv.style.display = 'block';
            responseDiv.className = 'response';
            if (isError) responseDiv.classList.add('error');
            if (isStreaming) responseDiv.classList.add('streaming');
            responseDiv.textContent = content;
        }
        
        function appendResponse(content) {
            responseDiv.textContent += content;
        }
        
        function getFormData() {
            return {
                userToken: document.getElementById('userToken').value,
                model: document.getElementById('model').value,
                message: document.getElementById('message').value,
                temperature: parseFloat(document.getElementById('temperature').value),
                maxTokens: parseInt(document.getElementById('maxTokens').value)
            };
        }
        
        testChatBtn.addEventListener('click', async () => {
            const data = getFormData();
            
            if (!data.userToken.trim()) {
                showResponse('Please enter a user token', true);
                return;
            }
            
            if (!data.message.trim()) {
                showResponse('Please enter a message', true);
                return;
            }
            
            testChatBtn.disabled = true;
            testStreamBtn.disabled = true;
            testToolsBtn.disabled = true;
            
            try {
                showResponse('Sending request through gateway...');
                
                const client = new LLMClient({
                    userToken: data.userToken,
                    model: data.model
                });
                
                let response;
                
                // åˆ¤æ–­æ˜¯å¦æ˜¯embeddingæ¨¡å‹
                if (data.model.includes('embedding') || data.model.includes('embed')) {
                    response = await client.embedding({
                        input: data.message,
                        model: data.model
                    });
                    
                    // æ ¼å¼åŒ–embeddingå“åº”
                    const formattedResponse = response.map((item, index) => 
                        `Embedding ${index + 1}:\nDimensions: ${item.embedding.length}\nFirst 10 values: [${item.embedding.slice(0, 10).map(v => v.toFixed(6)).join(', ')}...]`
                    ).join('\n\n');
                    
                    showResponse(`âœ… Success via Gateway!\n\n${formattedResponse}`);
                } else {
                    response = await client.chat({
                        messages: [{ role: 'user', content: data.message }],
                        temperature: data.temperature,
                        maxTokens: data.maxTokens
                    });
                    
                    showResponse(`âœ… Success via Gateway!\n\n${response}`);
                }
                
            } catch (error) {
                showResponse(`âŒ Gateway Error: ${error.message}`, true);
            } finally {
                testChatBtn.disabled = false;
                testStreamBtn.disabled = false;
                testToolsBtn.disabled = false;
            }
        });
        
        testStreamBtn.addEventListener('click', async () => {
            const data = getFormData();
            
            if (!data.userToken.trim()) {
                showResponse('Please enter a user token', true);
                return;
            }
            
            if (!data.message.trim()) {
                showResponse('Please enter a message', true);
                return;
            }
            
            testChatBtn.disabled = true;
            testStreamBtn.disabled = true;
            testToolsBtn.disabled = true;
            
            try {
                showResponse('ğŸŒŠ Streaming through gateway...\n\n', false, true);
                
                const client = new LLMClient({
                    userToken: data.userToken,
                    model: data.model
                });
                
                const stream = client.chatStream({
                    messages: [{ role: 'user', content: data.message }],
                    temperature: data.temperature,
                    maxTokens: data.maxTokens
                });
                
                for await (const chunk of stream) {
                    appendResponse(chunk);
                }
                
            } catch (error) {
                showResponse(`âŒ Gateway Stream Error: ${error.message}`, true);
            } finally {
                testChatBtn.disabled = false;
                testStreamBtn.disabled = false;
                testToolsBtn.disabled = false;
            }
        });

        testToolsBtn.addEventListener('click', async () => {
            const data = getFormData();
            
            if (!data.userToken.trim()) {
                showResponse('Please enter a user token', true);
                return;
            }
            
            if (!data.message.trim()) {
                showResponse('Please enter a message', true);
                return;
            }
            
            testChatBtn.disabled = true;
            testStreamBtn.disabled = true;
            testToolsBtn.disabled = true;
            
            try {
                showResponse('ğŸ› ï¸ Testing tools through gateway...\n\n');
                
                // é‡æ–°å¯¼å…¥ä»¥ç¡®ä¿æœ€æ–°çŠ¶æ€
                const { toolRegistry } = await import('./src/tools/registry.js');
                const toolNames = toolRegistry.getToolNames();
                appendResponse(`Registered tools: ${toolNames.join(', ')}\n\n`);
                
                // è·å–å·¥å…·å®šä¹‰XML
                const functionsXML = getFunctionsXML();
                appendResponse(`Available tools:\n${functionsXML}\n\n`);
                
                if (!functionsXML.trim()) {
                    appendResponse('âŒ ERROR: No tools are registered!\n\n');
                    appendResponse('Please check the console for initialization errors.\n');
                    return;
                }
                
                // æ„å»ºåŒ…å«å·¥å…·å®šä¹‰çš„ç³»ç»Ÿæç¤º
                const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š

${functionsXML}

é‡è¦è¯´æ˜ï¼š
1. å½“ä½ éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯ã€å®æ—¶æ•°æ®æˆ–ä½ çŸ¥è¯†åº“ä¸­æ²¡æœ‰çš„ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ä½¿ç”¨web_searchå·¥å…·
2. ä½¿ç”¨ä»¥ä¸‹XMLæ ¼å¼è°ƒç”¨å·¥å…·ï¼š
<function_calls>
<invoke name="web_search">
<parameter name="search_input">å…·ä½“çš„æœç´¢å†…å®¹</parameter>
</invoke>
</function_calls>

3. å¯¹äºä»¥ä¸‹ç±»å‹çš„é—®é¢˜ï¼Œä½ åº”è¯¥ä½¿ç”¨web_searchå·¥å…·ï¼š
   - æœ€æ–°æ–°é—»ã€æ—¶äº‹
   - å®æ—¶æ•°æ®ï¼ˆè‚¡ä»·ã€å¤©æ°”ç­‰ï¼‰
   - 2024å¹´ä¹‹åçš„ä¿¡æ¯
   - å…·ä½“çš„äº‹å®æŸ¥è¯¢

ç”¨æˆ·é—®é¢˜ï¼š${data.message}

è¯·åˆ†æè¿™ä¸ªé—®é¢˜æ˜¯å¦éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯ï¼Œå¦‚æœéœ€è¦ï¼Œè¯·ä½¿ç”¨web_searchå·¥å…·ã€‚`;

                // åˆ›å»ºLLMå®¢æˆ·ç«¯ - ä½¿ç”¨ç½‘å…³
                const client = new LLMClient({
                    userToken: data.userToken,
                    model: data.model
                });
                
                // å‘é€è¯·æ±‚åˆ°LLM
                appendResponse('ğŸ“¤ Sending request to LLM via gateway...\n\n');
                const llmResponse = await client.chat({
                    messages: [{ role: 'user', content: systemPrompt }],
                    temperature: data.temperature,
                    maxTokens: data.maxTokens
                });
                
                appendResponse(`ğŸ¤– LLM Response:\n${llmResponse}\n\n`);
                
                // è§£æå¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
                appendResponse('ğŸ” Parsing and executing function calls...\n\n');
                const toolResults = await parseAndExecuteFunctionCalls(llmResponse);
                
                if (toolResults.length > 0) {
                    appendResponse(`ğŸ› ï¸ Tool execution results:\n${JSON.stringify(toolResults, null, 2)}\n\n`);
                    
                    // å¦‚æœæœ‰å·¥å…·æ‰§è¡Œç»“æœï¼Œå‘é€å›LLMè·å–æœ€ç»ˆå›å¤
                    const finalPrompt = `åŸºäºä»¥ä¸‹å·¥å…·æ‰§è¡Œç»“æœï¼Œè¯·ç»™ç”¨æˆ·ä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›å¤ï¼š

å·¥å…·æ‰§è¡Œç»“æœï¼š
${JSON.stringify(toolResults, null, 2)}

ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š${data.message}

è¯·åŸºäºå·¥å…·è¿”å›çš„å®é™…ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚`;

                    appendResponse('âœ¨ Getting final response from LLM via gateway...\n\n');
                    const finalResponse = await client.chat({
                        messages: [{ role: 'user', content: finalPrompt }],
                        temperature: data.temperature,
                        maxTokens: data.maxTokens
                    });
                    
                    appendResponse(`ğŸ“ Final Response:\n${finalResponse}`);
                } else {
                    appendResponse('â„¹ï¸ No function calls found in LLM response.\n');
                    appendResponse('The LLM decided not to use any tools for this query.');
                }
                
            } catch (error) {
                console.error('Tools test error:', error);
                showResponse(`âŒ Gateway Tools Error: ${error.message}\n\nStack trace:\n${error.stack}`, true);
            } finally {
                testChatBtn.disabled = false;
                testStreamBtn.disabled = false;
                testToolsBtn.disabled = false;
            }
        });
        
        clearBtn.addEventListener('click', () => {
            responseDiv.style.display = 'none';
            responseDiv.textContent = '';
        });
    </script>
</body>
</html> 